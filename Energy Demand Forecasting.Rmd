---
title: "Forecasting Swiss Energy Demand"
output: 
  html_document:
    theme: readable
    toc: TRUE
    toc_depth: 3
    toc_float: TRUE
    df_print: paged
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

![](Graphics/bulb.jpg)

<style>
body {
text-align: justify}
</style>

```{css, echo=FALSE}
pre, code {white-space:pre !important; overflow-x:auto}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(tidymodels)
library(textrecipes)
library(doParallel)
library(snow)
library(vip)
library(broom)
library(car)
library(stacks)
library(lubridate)
library(modeltime)
library(timetk)
```

***
### The Project
***

TBD

<br>

***
### Data Procurement and Cleaning
***

Firstly, I start by loading the data. Looking at the first 5 rows:

```{r, echo=FALSE}
data <- readxl::read_excel("Data/5 EnergieEndverbrauch2009-2022.xlsx") %>% 
  janitor::clean_names() %>% 
  rename(date = zeitpunkt, kwh = k_wh)
```

```{r class.source = 'fold-show'}
glimpse(data)
```

There are no missing values. However, the frequency is too granular. For modelling purposes, I want to aggregate to daily values and filter out everything after 2019 to exclude the effect of the pandemic.

```{r class.source = 'fold-show'}
data <- data %>% 
  mutate(year = year(date),
         day_in_year = yday(date)) %>% 
  filter(year <= 2021) %>% 
  group_by(year, day_in_year) %>% 
  summarise(date = last(date) %>% as.Date(),
            mwh = sum(kwh)/1e3) %>% 
  ungroup()

summary(data)
```

Now we have got ten years worth of training data (2009-2018) and one year worth of testing data (2019).

<br>

##### Temperature Data

Got this document from [opendata.swiss](https://opendata.swiss/de/dataset/klimamessnetz-tageswerte).

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("Graphics/climatological network_desc.png")
```

This link led to this document, detailing various weather stations:

```{r}
read_csv("Data/liste-download-nbcn-d.csv")
```

Using the URLs to access the actual weather data for selected weather stations:

```{r, eval=FALSE}
temp_data <- read_csv("Data/liste-download-nbcn-d.csv") %>%
  filter(`station/location` %in% c("SMA", "GVE", "BAS", "DAV","LUG", "STG",
                                   "ALT", "NEU", "BER", "LUZ")) %>%
  mutate(station_data = map(`URL Previous years (verified data)`,
                            ~ read.csv(.x, sep = ";")),
         station_data = map(station_data,
                            ~ select(.x, date, tre200d0)),
         station_data = map(station_data,
                            ~ na_if(.x, "-")),
         station_data = map(station_data,
                            ~ .x %>%
                              mutate(date = as.character(date),
                                     tre200d0 = as.numeric(tre200d0)))) %>%
  select(Station, `station/location`, Canton, station_data) %>%
  unnest(station_data) %>%
  mutate(date = ymd(date)) %>%
  select(-Station, -Canton) %>%
  pivot_wider(names_from = `station/location`, values_from = "tre200d0")
```

```{r, eval=FALSE, echo=FALSE}
write_csv(temp_data, "Data/temp_data.csv")
```


```{r, echo=FALSE}
temp_data <- read_csv("Data/temp_data.csv")
```

Left-join temperature data to the clean electricity usage data and create average temperature column:

```{r}
data <- data %>% 
  left_join(temp_data, by = "date") %>% 
  mutate(avg_temp = rowMeans(select(., ALT:STG)))

summary(data)
```

Data is clean and ready to be used for model training. I split it into pre- and post-COVID for later test of the model regarding robustness during corona years:

```{r}
data <- data %>% 
  filter(year <= 2019)

data_corona <- data %>% 
  filter(year > 2019)
```

Only the data prior to 2019 is used for the modelling.

<br >

***
### Exploratory Data Analysis
***

```{r, dpi=300, message=F, warning=FALSE}
data %>% 
  mutate(day_in_week = wday(date),
         day = wday(date, label = T),
         weekend = case_when(
           day_in_week %in% c(7) ~ "Saturday",
           day_in_week %in% c(1) ~ "Sunday",
           TRUE ~ "Work Day") %>% 
           factor(levels = c("Work Day", "Saturday", "Sunday"))) %>% 
  ggplot(aes(day_in_year, mwh, colour = weekend)) +
  geom_point(alpha = 0.4) +
  labs(title = "On Sundays, You Shall Not Work: Swiss End-User Electricity Consumption",
       subtitle = "For each day in the year (1-365), 11 daily consumption points from the period 2009 to 2019 are plotted.\nColouring indicates if a day lies on a weekend or not.",
       caption = "Data Source: Swissgrid, Period 2009-2019",
       x = "Day Of The Year (1-365)",
       y = "Daily Consumption",
       colour = NULL) +
  scale_x_continuous(breaks = c(1, seq(50,366,50))) +
  scale_y_continuous(labels = comma_format(suffix = " MWh")) +
  ggsci::scale_colour_jama() +
  theme_light() +
  theme(plot.title = element_text(face = "bold", size = 14),
        plot.subtitle = element_text(face = "italic", size = 10,
                                     colour = "grey50"),
        plot.caption = element_text(face = "italic", size = 9,
                                    colour = "grey50"),
        legend.position = "right")
```

From the above chart, it becomes clear that the demand follows a strong intra-year pattern. Additionally, there is a seasonality component contained within each week. Monthly patterns are not discernible.

```{r, dpi=300, message=F, warning=FALSE}
data %>% 
  filter(year == 2010) %>%
  ggplot(aes(date, mwh)) +
  geom_line() +
  labs(title = "Daily Energy Consumption in 2010",
       y = "Daily Consumption",
       x = NULL) +
  scale_y_continuous(labels = comma_format(suffix = " MWh")) +
  theme_light() +
  theme(plot.title = element_text(face = "bold", size = 14),
        plot.subtitle = element_text(face = "italic", size = 10,
                                     colour = "grey50"),
        plot.caption = element_text(face = "italic", size = 9,
                                    colour = "grey50"),
        legend.position = "right")
```

Temperature development at different stations:

```{r}
data %>% 
  filter(year == 2019) %>% 
  select(-c(year, day_in_year, mwh)) %>% 
  pivot_longer(-date) %>% 
  ggplot(aes(date, value, colour = name)) +
  geom_line(size = 0.75, alpha = 0.5) +
  theme_bw()
```

Average temperature development and electricity usage:

```{r}
data %>% 
  select(date, avg_temp, mwh) %>%  
  mutate(day_in_week = wday(date),
         day = wday(date, label = T),
         weekend = case_when(
           day_in_week %in% c(7) ~ "Saturday",
           day_in_week %in% c(1) ~ "Sunday",
           TRUE ~ "Work Day") %>% 
           factor(levels = c("Work Day", "Saturday", "Sunday"))) %>% 
  ggplot(aes(avg_temp, mwh, colour = weekend)) +
  geom_point(alpha = 0.5, size = 1) +
  geom_smooth(size = 0.5, se = F) +
  labs(title = "Relation Between Energy Usage And Temperature",
       subtitle = "TBD",
       y = NULL,
       x = "Average Temperature",
       colour = NULL) +
  scale_y_continuous(labels = scales::comma_format(suffix = " MWh")) +
  scale_x_continuous(labels = scales::comma_format(suffix = "Â°")) +
  ggsci::scale_colour_jama() +
  theme_bw() +
  theme(plot.title = element_text(face = "bold", size = 14),
        plot.subtitle = element_text(face = "italic", size = 10,
                                     colour = "grey50"),
        plot.caption = element_text(face = "italic", size = 9,
                                    colour = "grey50"),
        legend.position = "right")

```

<br>

***
### Building A Model
***

In this post, I am not going to use usual time series forecasting techniques, but I'll rely on machine learning methods instead.

Creating splits:

```{r class.source = 'fold-show'}
dt_split <- data %>% 
  time_series_split(date_var = date, assess = "1 year", cumulative = T)

dt_train <- training(dt_split)
dt_test <- testing(dt_split)

folds <- vfold_cv(dt_train, v = 5)
```

Visualising the train/test split, it becomes very clear, what the goal will be: Forecasting the year 2019, for which we have the true data and are able to compute metrics to evaluate model performance.

```{r, dpi=300, fig.height=4.95, fig.width=8}
bind_rows(
  dt_train %>% mutate(id = "training"),
  dt_test %>% mutate(id = "testing")
) %>% 
  ggplot(aes(date, mwh, colour = id)) +
  geom_line() +
  scale_colour_manual(values = c("firebrick", "dodgerblue")) +
  labs(title = "Training/Testing Split") +
  scale_y_continuous(labels = comma_format()) +
  theme_light() +
  theme(plot.title = element_text(face = "bold", size = 14),
        plot.subtitle = element_text(face = "italic", size = 10,
                                     colour = "grey50"),
        plot.caption = element_text(face = "italic", size = 9,
                                    colour = "grey50"),
        legend.position = "right")
```

Creating a recipe for data preprocessing and squeezing as much information from the date column as possible.

```{r class.source = 'fold-show'}
model_rec <- recipe(mwh ~ .,
                    data = dt_train) %>%
  step_date(date) %>%
  step_holiday(date, holidays = timeDate::listHolidays("CH")) %>%
  step_mutate(month = lubridate::month(date),
              year_half = lubridate::semester(date) %>% as.factor,
              week_day = lubridate::wday(date),
              week_in_year = lubridate::week(date),
              quarter = lubridate::quarter(date),
              date_christmas = ifelse(between(day_in_year, 358, 366),
                                      1, 0),
              day_in_year = as.factor(day_in_year)) %>% 
  step_rm(date) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  step_zv()

model_rec %>% prep() %>% juice() %>% glimpse()
```

```{r class.source = 'fold-show'}
en_spec <- linear_reg(penalty = 0.02, mixture = 0.5) %>% 
  set_engine("glmnet") %>% 
  set_mode("regression")

xg_spec <- boost_tree(trees = 1000) %>% 
  set_engine("xgboost") %>% 
  set_mode("regression")

rf_spec <- rand_forest(trees = 500) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")
```

Without using resamples or hyperparameter tuning, the workflows can immediately be entirely fit to the training data.

```{r class.source = 'fold-show', eval=FALSE}
en_wf_fit <- workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(en_spec) %>% 
  fit(dt_train)

xg_wf_fit <- workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(xg_spec) %>% 
  fit(dt_train)

rf_wf_fit <- workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(rf_spec) %>% 
  fit(dt_train)
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(en_wf_fit, "Models/en_wf_fit.rds")
saveRDS(xg_wf_fit, "Models/xg_wf_fit.rds")
saveRDS(rf_wf_fit, "Models/rf_wf_fit.rds")
```

```{r, echo=FALSE}
en_wf_fit <- readRDS("Models/en_wf_fit.rds")
xg_wf_fit <- readRDS("Models/xg_wf_fit.rds")
rf_wf_fit <- readRDS("Models/rf_wf_fit.rds")
```


***
### Evaluating Model Performance
***

With the fitted models, I can now make predictions on the holdout data:

```{r class.source='fig-show'}
models <- tibble(
  type = c("RF", "EN", "GB"),
  wflow = list(rf_wf_fit, en_wf_fit, xg_wf_fit),
  predictions = map(.x = wflow, .f = ~ augment(.x, dt_test))
)

models
```

From this, let's extract the predictions for each model:

```{r class.source='fig-show'}
predictions <- models %>% 
  select(-wflow) %>% 
  unnest(predictions)

predictions
```

Defining a set of metric, I can now compare the performance of the three models with default parameters:

```{r, dpi=300, fig.height=4.95, fig.width=8, warning=FALSE, message=FALSE}
evaluation_metrics <- metric_set(rsq, rmse, mae)

predictions %>% 
  group_by(type) %>% 
  evaluation_metrics(truth = mwh, estimate = .pred) %>% 
  ggplot(aes(type, .estimate, colour = type)) +
  geom_point(size = 3, shape = 18) +
  facet_wrap(~ .metric, scales = "free_y") +
  theme_light() +
  theme(legend.position = "none",
        panel.grid.major.x = element_blank())

predictions %>% 
  group_by(type) %>% 
  evaluation_metrics(truth = mwh, estimate = .pred) %>% 
  select(-.estimator) %>% 
  pivot_wider(names_from = ".metric", values_from = ".estimate") %>% 
  arrange(-rsq)
```

Clearly, random forest and gradient boosting have outperformed elastic net.

```{r, dpi=300, fig.height=4.95, fig.width=8}
predictions %>% 
  ggplot(aes(mwh, .pred)) +
  geom_point(alpha = 0.2, colour = "midnightblue", size = 2) +
  facet_wrap(~ type) +
  geom_abline(lty = "dashed", colour = "grey50") +
  scale_x_continuous(labels = scales::comma_format()) +
  scale_y_continuous(labels = scales::comma_format()) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r, dpi=300, fig.height=4.95, fig.width=8}
predictions %>% 
  rename(actual = mwh, prediction = .pred) %>% 
  select(type, date, actual, prediction) %>% 
  pivot_longer(-c(type, date)) %>% 
  ggplot(aes(date, value, colour = name)) +
  geom_line(size = 0.5) +
  labs(x = NULL,
       y = "mwh",
       colour = NULL) +
  facet_wrap(~ type, ncol = 1) +
  ggsci::scale_colour_jama() +
  scale_y_continuous(labels = scales::comma_format()) +
  theme_bw()
```

***
### Doubling Down On Tree Ensembles
***

With the knowledge from above, let's now tune hyperparameters for a random forest and gradient boosting model, to see whether we can fill the gaps of the standard models.

```{r}
rf_spec <- rand_forest(mtry = tune(),
                       min_n = tune(),
                       trees = tune()) %>%
  set_engine("ranger") %>%
  set_mode("regression")

rf_wflow <- workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(rf_spec)

rf_grid <- grid_latin_hypercube(finalize(mtry(), dt_train),
                                min_n(),
                                trees(),
                                size = 50)
```

```{r}
gb_spec <- boost_tree(mtry = tune(),
                      trees = tune(),
                      min_n = tune(),
                      tree_depth = tune(),
                      learn_rate = tune(),
                      loss_reduction = tune()) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

gb_wflow <- workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(gb_spec)

gb_grid <- grid_latin_hypercube(finalize(mtry(), dt_train),
                                trees(),
                                min_n(),
                                tree_depth(),
                                learn_rate(),
                                loss_reduction(),
                                size = 100)
```

```{r, eval=FALSE}
# Random Forest
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

start_time <- Sys.time()

cl <- makePSOCKcluster(6)
registerDoParallel(cl)

rf_tune <- tune_grid(object = rf_wflow,
                     grid = rf_grid,
                     resamples = folds)

stopCluster(cl)
unregister_dopar()

end_time <- Sys.time()
end_time - start_time

# Gradient Boosting
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
  }

start_time <- Sys.time()

cl <- makePSOCKcluster(6)
registerDoParallel(cl)

gb_tune <- tune_grid(object = gb_wflow,
                     grid = gb_grid,
                     resamples = folds)

stopCluster(cl)
unregister_dopar()

end_time <- Sys.time()
end_time - start_time
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(rf_tune, "Models/rf_tune.rds")
saveRDS(gb_tune, "Models/gb_tune.rds")
```

```{r, echo=FALSE}
rf_tune <- readRDS("Models/rf_tune.rds")
gb_tune <- readRDS("Models/gb_tune.rds")
```

Comparing the model performances of both random forest and gradient boosting:

```{r}
rf_tune %>% 
  show_best(metric = "rsq")
```

```{r}
gb_tune %>% 
  show_best(metric = "rsq")
```

Gradient boosting performed slightly better. Therefore, it will be the final model.

Fitting onto the entire training data set:

```{r, eval=FALSE}
gb_final_fit <- gb_wflow %>% 
  finalize_workflow(select_best(gb_tune, metric = "rsq")) %>% 
  last_fit(dt_split)
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(gb_final_fit, "Models/gb_final_fit.rds")
```

```{r, echo=FALSE}
gb_final_fit <- readRDS("Models/gb_final_fit.rds")
```

Evaluating out-of-sample performance:

```{r}
gb_final_fit %>% 
  collect_predictions() %>% 
  ggplot(aes(mwh, .pred)) +
  geom_point(alpha = 0.5, size = 1.5, colour = "midnightblue") +
  labs(title = "Out-Of-Sample Gradient Boosting Model Performance",
       y = "Estimate",
       x = "Truth") +
  geom_abline(colour = "grey50", lty = "dashed") +
  scale_y_continuous(labels = scales::comma_format(suffix = " MWh")) +
  scale_x_continuous(labels = scales::comma_format(suffix = " MWh")) +
  theme_bw() +
  theme(plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(face = "italic", size = 12,
                                     colour = "grey50"))
```

Out-of-sample metrics:

```{r}
gb_final_fit %>% 
  collect_predictions() %>% 
  evaluation_metrics(truth = mwh, estimate = .pred)
```

Out-of-sample time series:

```{r, fig.width=10, fig.height=3, dpi=320}
gb_final_fit %>% 
  extract_workflow() %>% 
  augment(dt_test) %>% 
  transmute(date, prediction = .pred, actual = mwh) %>% 
  pivot_longer(-date) %>% 
  ggplot(aes(date, value, colour = name)) +
  geom_line(alpha = 0.75, size = 0.75) +
  labs(title = "Out-of-sample Time Series",
       y = NULL,
       x = NULL,
       colour = NULL) +
  ggsci::scale_colour_jama() +
  scale_y_continuous(labels = scales::comma_format(suffix = " MWh")) +
  theme_bw() +
  theme(plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(face = "italic", size = 12,
                                     colour = "grey50"))
```

Mean Absolute Error as percentage of average time holdout target value:

```{r}
mean_abs_error <- gb_final_fit %>%
  extract_workflow() %>% 
  augment(dt_test) %>% 
  mae(mwh, .pred) %>% 
  pull(.estimate)

mean_mwh <- gb_final_fit %>%
  extract_workflow() %>% 
  augment(dt_test) %>% 
  summarise(mean(mwh)) %>% 
  pull()

mean_abs_error/mean_mwh
```

Deviation by date:

```{r}
gb_final_fit %>% 
  extract_workflow() %>% 
  augment(dt_test) %>% 
  mutate(delta = .pred/mwh-1,
         exceedance = ifelse(abs(delta) > 0.05, 1, 0) %>% as.factor()) %>% 
  ggplot(aes(date, delta, colour = exceedance)) +
  geom_point() +
  ggsci::scale_colour_jama()
```

```{r}
gb_final_fit %>% 
  extract_workflow() %>% 
  augment(dt_test) %>% 
  mutate(delta = .pred/mwh-1) %>% 
  transmute(day = yday(date), delta) %>% 
  acf()
```

Which days still show high deviation? Find out what happened on these days in 2019

```{r}
gb_final_fit %>% 
  extract_workflow() %>% 
  augment(dt_test) %>% 
  mutate(delta = .pred/mwh-1,
         exceedance = ifelse(abs(delta) > 0.05, 1, 0) %>% as.factor()) %>% 
  filter(exceedance == 1) %>% 
  select(date, exceedance) %>% 
  print(n = 100)
```

The tuning managed to improve metrics.

<!-- How to construct confidence intervals? -->

```{r}
gb_final_fit %>%
  extract_workflow() %>% 
  augment(dt_test) %>% 
  mutate(lower_conf = .pred*(1-mean_abs_error/mean_mwh),
         higher_conf = .pred*(1+mean_abs_error/mean_mwh)) %>%  
  ggplot() +
  geom_line(aes(date, .pred), colour = "midnightblue", alpha = 0.5) +
  geom_line(aes(date, mwh), colour = "firebrick") +
  geom_ribbon(aes(x = date, ymin = lower_conf, ymax = higher_conf), 
              fill = "midnightblue", alpha = 0.25) +
  theme_light()
```


I hope this post has been interesting to you. In case of constructive feedback or if you want to exchange about this or a related topic, feel free to reach out.

Thank you for reading.

&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="https://www.linkedin.com/in/mathias-steilen/">Mathias Steilen</a></p>
&nbsp;